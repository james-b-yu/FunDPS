# Main options
outdir: "exps"  # Where to save the results
data: "data/darcy_hf/"  # Path to the dataset
resolution: 64  # Resolution of the dataset after downsampling
cond: false  # Train class-conditional model
arch: "ddpmpp-uno"  # Network architecture (options: ddpmpp, ncsnpp, adm, ddpmpp-uno)
precond: "edm"  # Preconditioning & loss function (options: vp, ve, edm)

# Hyperparameters
duration: 10  # Training duration in millions of images
batch: 32  # Total batch size
batch_gpu: null  # Limit batch size per GPU (optional)
nn_resolution: null  # Resolution of the network, defaults to resolution
cbase: 64  # Channel multiplier (optional, varies by default)
cres: [1,2,4,4]  # Channels per resolution (optional, varies by default)
lr: 1.0e-4  # Learning rate
lr_rampup: 5  # # Learning rate ramp-up duration in millions of images
ema: 0.5  # EMA half-life in millions of images
dropout: 0.13  # Dropout probability
augment: 0.12  # Augment probability
xflip: false  # Enable dataset x-flips

# Neural Operator-related
attn_resolutions: [8]  # Resolutions to apply attention
num_blocks: 4  # Number of blocks in the network
fmult: 0.5  # Feature multiplier
rank: 0.1  # Rank of the operator
rbf_scale: 0.05  # RBF scale

# Performance-related
fp16: false  # Enable mixed-precision training
ls: 1  # Loss scaling
bench: true  # Enable cuDNN benchmarking
cache: true  # Cache dataset in CPU memory
workers: 4  # DataLoader worker processes

# I/O-related
tick: 10  # How often to print progress (in thousands of images)
snap: 50  # How often to save snapshots (in ticks)
dump: 250  # How often to dump state (in ticks)
seed: null  # Random seed (optional, random if not specified)
resume: null  # Resume from previous training state (path to training-state-*.pt file)
dry_run: false  # Print training options and exit without training

# Wandb configuration
wandb: "disabled"  # Weights & Biases mode (options: online, offline, disabled)
name: "darcy_no_wandb"  # Wandb run name
